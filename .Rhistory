xl2 <- c(e2[1], e2[2])
yl2 <- c(e2[3], e2[4])
x_breaks <- c(round(xl2[1], 0), round(xl2[1], 0) + round((xl2[2] - xl2[1]) / 2, 0), round(xl2[1], 0) + 2 * round((xl2[2] - xl2[1]) / 2, 0))
y_breaks <- c(round(yl2[1], 0), round(yl2[1], 0) + round((yl2[2] - yl2[1]) / 2, 0), round(yl2[1], 0) + 2 * round((yl2[2] - yl2[1]) / 2, 0))
ggplot() +
geom_spatvector(data = fao2, aes(fill = n2)) +
geom_polygon(data = world, aes(x = long, y = lat, group = group), fill = "lightgrey", color = "#282828") +
coord_sf(xlim = c(-1758764, 6683391), ylim = c(861188, 7369164.9), expand = TRUE) +
labs(fill = "Driver's coverage\n per sub-area") +
xlab("Longidute") +
ylab("Latitude")
?sampleMcmc
?HMSC::sampleMcmc
?Hmsc::sampleMcmc
source("D:/OneDrive - Coispa Tecnologia & Ricerca S.C.A.R.L/B-USEFUL/jSDM/HMSC_model_202402/File per il cluster Drago/007_AB_LNP_chains_1_c1.r")
s
s
rm(list=ls())
library(Hmsc)
library(dplyr)
setwd("D:\\OneDrive - Coispa Tecnologia & Ricerca S.C.A.R.L\\B-USEFUL\\jSDM\\HMSC_model_202402")
model_name <- "007_AB_LNP"
chain <- 1
thin <- 50
samples <- 250
distribution <- "lognormal poisson" #"normal"
env.vars <- c("depth", "sst_anom", "so_anom", "chl_anom", "btemp_anom", "bottom")
load("ALL_GSAs_EMED_HMSC_data_ALL_GSA_20240214.Rdata", verbose=T)
if (distribution =="normal"){
# Normal model
Y[is.na(Y)] <- 0
}
if (distribution =="probit"){
# Probit model
Y[is.na(Y)] <- 0
Y[Y >0 ] <- 1
}
if (distribution =="lognormal poisson"){
# Lognormal poisson
Y[is.na(Y)] <- 0
Y <- log(Y + 1)
}
### 2.1 Define regression model for environmental covariates ####
X <- X[, colnames(X) %in% env.vars]
X$depth <- log(X$depth)
colnames(X)[which(colnames(X)=="depth")] <- "log.depth"
XFormula = as.formula(paste("~",paste(colnames(X), collapse="+")))
XFormula
### 2.2 Define regression model for traits ####
TrFormula = as.formula(paste("~",paste(colnames(Tr), collapse="+")))
TrFormula
### 2.3 Set up study design with random effects ####
row.names(S) <- seq(1,nrow(S),1)
dupl <- which(duplicated(S[,c('lon','lat')]))
i=1
for (i in 1:length(dupl)) {
ds <- S[which(S$lon==S$lon[dupl[i]] & S$lat==S$lat[dupl[i]]), ]
ds <- ds[-1,]
lon <- ds$lon[1]
lat <- ds$lat[1]
for (n in 1:nrow(ds)){
lon <- lon +0.000001
lat <- lat +0.000001
S[dupl[i],"lon"] <- lon
S[dupl[i],"lat"] <- lat
}
}
# S<-S[!duplicated(S[,c('lon','lat')]),]
X<-X[rownames(X)%in%S$id,]
Y<-Y[rownames(Y)%in%S$id,]
X$bottom <- as.factor(X$bottom)
studyDesign = data.frame(sample = as.factor(S$id),
year = as.factor(S$year),
grid.cell=as.factor(S$grid.id),
grid.lon=as.factor(round(S$grid.lon,5)),
grid.lat=as.factor(round(S$grid.lat,5))
)# it must contain all columns of random factors
rL.year = HmscRandomLevel(units = levels(studyDesign$year))# add year as random effect
knots=S[, c(7:9)]
knots$grid.lon <- round(knots$grid.lon,5)
knots$grid.lat <- round(knots$grid.lat,5)
knots <- data.frame(knots %>% group_by(grid.id,grid.lon,grid.lat) %>% dplyr::summarise())
xy <- data.frame(S[match(unique(S$grid.id), S$grid.id), c("grid.lon", "grid.lat")])
rownames(xy) <- unique(S$grid.id)
rL.location <- HmscRandomLevel(sData = xy, longlat = TRUE, sMethod = "NNGP", sKnot = knots[,2:3], nNeighbours = 10)
rL.location <- setPriors(rL.location, nfMin = 2, nfMax = 5)
### 2.4 Set up MCMC sample specifications ####
# thin = thin
# samples = samples
transient = ceiling(0.5*samples*thin)
nChains = 1
gc()
{
cat("--- Model definition\n")
m0 = Hmsc(Y = Y,
XData = X,
XFormula = XFormula,
TrFormula = TrFormula,
TrData = Tr,
phyloTree = P,
studyDesign = studyDesign,
ranLevels = list(year=rL.year, grid.cell = rL.location),
distr = distribution)
m0
cat("--- Star modelling\n")
t0 <- Sys.time()
m = sampleMcmc(m0, thin = thin, samples = samples, transient = transient, nChains = nChains, nParallel = nChains, initPar = "fixed effects") #
t1 <- Sys.time()
cat("--- End modelling\n")
}
t1-t0
cat("--- saving model\n")
filename =  paste(model_name,"_thin_", as.character(thin),"_samples_", as.character(samples),"_chains_", as.character(nChains), "_c",chain,".Rdata",sep = "")
save(m,file=filename)
cat("--- Model saved\n")
rm(list=ls())
library(Hmsc)
library(tidyverse)
library(viridis)
library(vioplot)
library(abind)
library(RColorBrewer)
library(ape)
library(corrplot)
library(snow)
# setwd("D:\\OneDrive - Coispa Tecnologia & Ricerca S.C.A.R.L\\B-USEFUL\\DRAGO cluster\\DATA\\EMED_003")
thin = 50
samples = 250
transient = ceiling(0.5*samples*thin)
nChains = 4
rm(list=ls())
setwd("D:\\OneDrive - Coispa Tecnologia & Ricerca S.C.A.R.L\\B-USEFUL\\jSDM\\HMSC_model_202402\\Risultati")
library(Hmsc)
library(tidyverse)
library(viridis)
library(vioplot)
library(abind)
library(RColorBrewer)
library(ape)
library(corrplot)
library(snow)
model_name <- "002b_ABUND"
# setwd("D:\\OneDrive - Coispa Tecnologia & Ricerca S.C.A.R.L\\B-USEFUL\\DRAGO cluster\\DATA\\EMED_003")
thin = 50
samples = 250
transient = ceiling(0.5*samples*thin)
nChains = 4
load("002b_ABUND_thin_50_samples_250_chains_1_c1.Rdata")
load(paste0(model_name,"_thin_50_samples_250_chains_1_c1.Rdata"))
m1 <- m
load(paste0(model_name,"_thin_50_samples_250_chains_1_c2.Rdata"))
m2 <- m
load(paste0(model_name,"_thin_50_samples_250_chains_1_c3.Rdata"))
m3 <- m
load(paste0(model_name,"_thin_50_samples_250_chains_1_c4.Rdata"))
m4 <- m
m <- c(m1,m2,m3,m4)
# 3. Check MCMC convergence diagnostics
mpost = convertToCodaObject(m)
summary(effectiveSize(mpost$Beta))
summary(effectiveSize(mpost$Gamma))
expected <- samples*nChains
expected
par(mfrow=c(1,3))
# Beta parameters (species-environment)
hist(effectiveSize(mpost$Beta), main="ess(beta)")
hist(gelman.diag(mpost$Beta, multivariate = FALSE)$psrf, main="psrf(beta)")
vioplot(gelman.diag(mpost$Beta,multivariate = FALSE)$psrf,main="psrf(beta)")
dev.copy(jpeg,paste0(model_name,'Beta_parameters.jpg'),height=5,width=8, units='in', res=300)
dev.off()
dev.copy(jpeg,paste0(model_name,'_Beta_parameters.jpg'),height=5,width=8, units='in', res=300)
dev.off()
load(paste0(model_name,"_thin_",thin,"_samples_",samples,"_chains_1_c1.Rdata"))
m1 <- m
# Gamma parameters (trait-environment)
hist(effectiveSize(mpost$Gamma), main="ess(gamma)")
hist(gelman.diag(mpost$Gamma, multivariate = FALSE)$psrf, main="psrf(gamma)")
vioplot(gelman.diag(mpost$Gamma,multivariate = FALSE)$psrf,main="psrf(gamma)")
dev.copy(jpeg,paste0(model_name,'_Gamma_parameters.jpg'),height=5,width=8, units='in', res=300)
dev.off()
# Omega
tmp = mpost$Omega[[1]]
z = ncol(tmp[[1]])
sel = sample(z, size=200)
for(i in 1:length(tmp)){
tmp[[i]] = tmp[[i]][,sel]
}
psrf.omega = gelman.diag(tmp,multivariate=FALSE)$psrf
par(mfrow=c(1,1))
hist(psrf.omega, xlab = "psrf (Omega)")
dev.copy(jpeg,paste0(model_name,'_Omega_parameters.jpg'),height=5,width=8, units='in', res=300)
dev.off()
#------------------------------
# 4. Post process model results
# 4.1 Compute predicted values
# compute predicted species abundance matrix/ posterior samples
predY=computePredictedValues(m)
save(predY,file=paste0(model_name,"_PredY.Rdata"))
# 4.2 Evaluate model fit (MF)
MF = evaluateModelFit(hM = m, predY = predY)
mean(MF$R2)
rm(list=ls())
library(Hmsc)
library(dplyr)
setwd("D:\\OneDrive - Coispa Tecnologia & Ricerca S.C.A.R.L\\B-USEFUL\\jSDM\\HMSC_model_202402")
model_name <- "007_AB_LNP"
chain <- 1
thin <- 50
samples <- 250
distribution <- "lognormal poisson" #"normal"
env.vars <- c("depth", "sst_anom", "so_anom", "chl_anom", "btemp_anom", "bottom")
###-----------------------###
###  SET-UP AND RUN HMSC  ###
###-----------------------###
load("ALL_GSAs_EMED_HMSC_data_ALL_GSA_20240214.Rdata", verbose=T)
if (distribution =="normal"){
# Normal model
Y[is.na(Y)] <- 0
}
if (distribution =="probit"){
# Probit model
Y[is.na(Y)] <- 0
Y[Y >0 ] <- 1
}
if (distribution =="lognormal poisson"){
# Lognormal poisson
Y[is.na(Y)] <- 0
Y <- log(Y + 1)
}
### 2.1 Define regression model for environmental covariates ####
X <- X[, colnames(X) %in% env.vars]
X$depth <- log(X$depth)
colnames(X)[which(colnames(X)=="depth")] <- "log.depth"
XFormula = as.formula(paste("~",paste(colnames(X), collapse="+")))
XFormula
### 2.2 Define regression model for traits ####
TrFormula = as.formula(paste("~",paste(colnames(Tr), collapse="+")))
TrFormula
### 2.3 Set up study design with random effects ####
row.names(S) <- seq(1,nrow(S),1)
dupl <- which(duplicated(S[,c('lon','lat')]))
i=1
for (i in 1:length(dupl)) {
ds <- S[which(S$lon==S$lon[dupl[i]] & S$lat==S$lat[dupl[i]]), ]
ds <- ds[-1,]
lon <- ds$lon[1]
lat <- ds$lat[1]
for (n in 1:nrow(ds)){
lon <- lon +0.000001
lat <- lat +0.000001
S[dupl[i],"lon"] <- lon
S[dupl[i],"lat"] <- lat
}
}
# S<-S[!duplicated(S[,c('lon','lat')]),]
X<-X[rownames(X)%in%S$id,]
Y<-Y[rownames(Y)%in%S$id,]
X$bottom <- as.factor(X$bottom)
studyDesign = data.frame(sample = as.factor(S$id),
year = as.factor(S$year),
grid.cell=as.factor(S$grid.id),
grid.lon=as.factor(round(S$grid.lon,5)),
grid.lat=as.factor(round(S$grid.lat,5))
)# it must contain all columns of random factors
rL.year = HmscRandomLevel(units = levels(studyDesign$year))# add year as random effect
knots=S[, c(7:9)]
knots$grid.lon <- round(knots$grid.lon,5)
knots$grid.lat <- round(knots$grid.lat,5)
knots <- data.frame(knots %>% group_by(grid.id,grid.lon,grid.lat) %>% dplyr::summarise())
xy <- data.frame(S[match(unique(S$grid.id), S$grid.id), c("grid.lon", "grid.lat")])
rownames(xy) <- unique(S$grid.id)
rL.location <- HmscRandomLevel(sData = xy, longlat = TRUE, sMethod = "NNGP", sKnot = knots[,2:3], nNeighbours = 10)
rL.location <- setPriors(rL.location, nfMin = 2, nfMax = 5)
### 2.4 Set up MCMC sample specifications ####
# thin = thin
# samples = samples
transient = ceiling(0.5*samples*thin)
nChains = 1
gc()
{
cat("--- Model definition\n")
m0 = Hmsc(Y = Y,
XData = X,
XFormula = XFormula,
TrFormula = TrFormula,
TrData = Tr,
phyloTree = P,
studyDesign = studyDesign,
ranLevels = list(year=rL.year, grid.cell = rL.location),
distr = distribution)
m0
cat("--- Star modelling\n")
t0 <- Sys.time()
m = sampleMcmc(m0, thin = thin, samples = samples, transient = transient, nChains = nChains, nParallel = nChains, initPar = "fixed effects") #
t1 <- Sys.time()
cat("--- End modelling\n")
}
t1-t0
cat("--- saving model\n")
filename =  paste(model_name,"_thin_", as.character(thin),"_samples_", as.character(samples),"_chains_", as.character(nChains), "_c",chain,".Rdata",sep = "")
save(m,file=filename)
cat("--- Model saved\n")
#----------
# t2 <- Sys.time()
# cat("--- starting Cross-validation\n")
# filename=paste0("CV_EMED_chains_",as.character(nChains),"_samples_",as.character(samples),"_thin_",as.character(m$thin),".Rdata")
#
# {
#     partition = createPartition(m, nfolds = 2, column = "grid.cell")
#     preds = computePredictedValues(m,partition=partition, nParallel = nChains)
#     MFCV = evaluateModelFit(hM=m, predY=preds)
#     save(partition,MFCV,file=filename)
# }
# cat("--- starting Cross-validation\n")
# t3 <- Sys.time()
# t3-t2
rm(list=ls())
library(ggpubr)
library(dplyr)
library(raster)
library(ggplot2)
library(inlmisc)
library(spdep)
library(rgdal)
library(terra)
library(sf)
library(inlmisc)
threshold <- 10
years <- c(2019:2021)
areas <- c(17,18)
GSAs <- paste(areas,collapse="")
scenarios <- "10perc_HS"
# set folder directory
root <- paste("D:/OneDrive - Coispa Tecnologia & Ricerca S.C.A.R.L/FBIT/FBIT_2022_",paste(GSAs,collapse=""),sep="")
pathdir <- file.path(root,"Displacement",scenarios)
dir.create(pathdir)
# load RBS shapefile
v <- vect(file.path(root,"Step_4","RBS_2017_2021_NA.shp"))
plot(v)
# data <- v[,c("csquares","X","Y","MSFDhab","medLong")]
data <- as.data.frame(v)
# r <- rasterFromXYZ(data[,c("X","Y","G")])
# r_sel <- r > thres_hot
# plot(r>thres_hot)
# dcells <- data[data$G >= thres_hot, ]
#
# writeRaster(r, file.path(pathdir,paste("Raster_Getis_sensitivity_",paste(range(years),sep="_",collapse="_"),".tif",sep="")),overwrite=TRUE)
#
# write.table(dcells, paste("D:\\OneDrive - Coispa Tecnologia & Ricerca S.C.A.R.L\\FBIT\\FBIT_2022_",GSAs,"\\Displacement\\",scenarios,"\\",scenarios,"_",GSAs,"_",paste(range(years),collapse=""),"_closure.csv",sep=""),sep=";",row.names=FALSE)
#
# #######################################
data$strata <- "slope"
data[data$Depth > -200, "strata"] <- "shelf"
data$hab_code <- paste(data$MSFDhab, data$strata,sep="_")
habs <- unique(data$hab_code)
i=1
cells_selected <- NULL
dft <- data[data$hab_code == habs[i], ]
dft
dft2 <- frank(dft, -medLong , -OT_SurfSAR)
dft2 <- data.table::frank(dft, -medLong , -OT_SurfSAR)
dft2
colnames(dft)
dft2 <- dft[, c("csquares", "hab_code", "medLong", "OT_SurfSAR")]
dft2$rank <- data.table::frank(dft2, -medLong , -OT_SurfSAR)
head(dft2)
dft2 <- dft2 %>% arrange(desc(rank))
head(dft2)
dft2 <- dft2 %>% arrange(rank)
head(dft2)
summary(dft2$OT_SurfSAR)
nc <- nrow(dft2)
if (nc >= 10) {
p <- round(nc/10,0)
} else {
p=0
}
dft2 <- dft2 %>% arrange(desc(rank))
nc <- nrow(dft2)
if (nc >= 10) {
p <- round(nc/10,0)
} else {
p=0
}
if (length(p)>0) {
cells_selected <- rbind(cells_selected, dft[1:p, ])
}
cells_selected
nrow(data)
nrow(cells_selected)
r_sel <- rasterFromXYZ(cells_selected[, c("X","Y","medLong")])
pol <- Grid2Polygons(r_sel, "layer", level = FALSE, cuts=2)
proj4string(pol) <- CRS("+init=epsg:4326")
# pol <- pol[pol$z==1,]
p <- disaggregate(pol)
p$z <- seq(1,length(p$z),1)
plot(p)
writeOGR(p,  paste("D:\\OneDrive - Coispa Tecnologia & Ricerca S.C.A.R.L\\FBIT\\FBIT_2022_",GSAs,"\\Displacement\\",scenarios,sep=""),paste(scenarios,"_",GSAs,"_",paste(range(years),collapse=""),"_closure",sep=""),driver="ESRI Shapefile",overwrite=TRUE)
xmin <- min(data$X,na.rm=TRUE)
xmax <- max(data$X,na.rm=TRUE)
for (i in 1:length(habs)) {
dft <- data[data$hab_code == habs[i], ]
dft <- dft %>% arrange(desc(medLong))
dft2 <- dft[, c("csquares", "hab_code", "medLong", "OT_SurfSAR")]
dft2$rank <- data.table::frank(dft2, -medLong , -OT_SurfSAR)
dft2 <- dft2 %>% arrange(desc(rank))
nc <- nrow(dft2)
if (nc >= 10) {
p <- round(nc/10,0)
} else {
p=0
}
if (length(p)>0) {
cells_selected <- rbind(cells_selected, dft[1:p, ])
}
}
nrow(data)
nrow(cells_selected)
r_sel <- rasterFromXYZ(cells_selected[, c("X","Y","medLong")])
pol <- Grid2Polygons(r_sel, "layer", level = FALSE, cuts=2)
proj4string(pol) <- CRS("+init=epsg:4326")
# pol <- pol[pol$z==1,]
p <- disaggregate(pol)
p$z <- seq(1,length(p$z),1)
plot(p)
xmin <- min(data$X,na.rm=TRUE)
xmax <- max(data$X,na.rm=TRUE)
ymin <- min(data$Y,na.rm=TRUE)
ymax <- max(data$Y,na.rm=TRUE)
xl <- c(xmin - (xmax - xmin) * 0.05, xmax + (xmax - xmin) * 0.05)
yl <- c(ymin - (ymax - ymin) * 0.05, ymax + (ymax - ymin) * 0.05)
x_breaks <- c(round(xmin, 0), round(xmin, 0) + round((xmax - xmin) / 2, 0), round(xmin, 0) + 2 * round((xmax - xmin) / 2, 0))
y_breaks <- c(round(ymin, 0), round(ymin, 0) + round((ymax - ymin) / 2, 0), round(ymin, 0) + 2 * round((ymax - ymin) / 2, 0))
world <- map_data("world")
ggplot() +
coord_sf(xlim = xl, ylim = yl, expand = FALSE) +
geom_tile(data = data, aes_string(x = "X", y = "Y", fill = "medLong")) +
scale_fill_gradientn(colours=c("blue","cyan","white", "yellow","red"))+
scale_x_continuous(breaks = x_breaks) +
scale_y_continuous(breaks = y_breaks) +
geom_polygon(data = world, aes(x = long, y = lat, group = group), fill = "lightgrey", color = "darkgrey") +
geom_polygon(data = p, aes(x = long, y = lat, group = group),fill=NA, color="black",size=0.8) +
theme_bw() +
xlab("long") +
ylab("lat") +
# labs(fill =response) +
ggtitle("Getis index")+
theme(plot.title = element_text(hjust = 0.5))
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, collapse = FALSE, tidy = FALSE)
# Sys.setenv(LANG = "en")
options(warn = -1)
library(readxl)
library(terra)
library(raster)
library(dplyr)
library(ggplot2)
library(RColorBrewer)
library(sp)
library(tidyterra)
library(plotly)
library(reshape2)
library(readxl)
datadir <- "D:\\OneDrive - Coispa Tecnologia & Ricerca S.C.A.R.L\\B-USEFUL\\Task 2.2\\zip_file\\data"
d <- read_xlsx(file.path(datadir,"DMP_AnnexDataInventory.xlsx"),  sheet = "Input-SurveyData_0224") #
d[d=="NA"] <- NA
eco <- vect(file.path(datadir, "shapefiles", "ICES_ecoregions_clipped.shp"))
eco_4326 <- eco
eco <- project(eco, "EPSG:3035")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, collapse = FALSE, tidy = FALSE)
# Sys.setenv(LANG = "en")
options(warn = -1)
library(readxl)
library(terra)
library(raster)
library(dplyr)
library(ggplot2)
library(RColorBrewer)
library(sp)
library(tidyterra)
library(plotly)
library(reshape2)
library(readxl)
datadir <- "D:\\OneDrive - Coispa Tecnologia & Ricerca S.C.A.R.L\\B-USEFUL\\Task 2.2\\zip_file\\data"
d <- read_xlsx(file.path(datadir,"DMP_AnnexDataInventory.xlsx"),  sheet = "Input-SurveyData_0224") #
d[d=="NA"] <- NA
eco <- vect(file.path(datadir, "shapefiles", "ICES_ecoregions_clipped.shp"))
eco_4326 <- eco
eco <- project(eco, "EPSG:3035")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, collapse = FALSE, tidy = FALSE)
# Sys.setenv(LANG = "en")
options(warn = -1)
library(readxl)
library(terra)
library(raster)
library(dplyr)
library(ggplot2)
library(RColorBrewer)
library(sp)
library(tidyterra)
library(plotly)
library(reshape2)
library(readxl)
datadir <- "D:\\OneDrive - Coispa Tecnologia & Ricerca S.C.A.R.L\\B-USEFUL\\Task 2.2\\zip_file\\data"
d <- read_xlsx(file.path(datadir,"DMP_AnnexDataInventory.xlsx"),  sheet = "Input-SurveyData_0224") #
d[d=="NA"] <- NA
eco <- vect(file.path(datadir, "shapefiles", "ICES_ecoregions_clipped.shp"))
eco_4326 <- eco
eco <- project(eco, "EPSG:3035")
eco
plot(eco)
eco_4326 <- eco
eco <- project(eco, "EPSG:3035")
